{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d642147b599d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0meyes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meye_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaleFactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminNeighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meyes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture('http://192.168.1.5:4747/mjpegfeed') \n",
    "eye_cascade = cv2.CascadeClassifier('x.xml')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "counter=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while(True): \n",
    "      \n",
    "    # Capture the video frame \n",
    "    # by frame \n",
    "    ret, frame = vid.read()    \n",
    " \n",
    "    if(type(frame)!=None):\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        eyes = eye_cascade.detectMultiScale( img,scaleFactor = 1.1, minNeighbors = 5)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(img,(ex,ey),(ex+ew,ey+eh),(255,0,0),5)\n",
    "\n",
    "\n",
    "        if(eyes==()):\n",
    "            counter+=1\n",
    "            if(counter>10):\n",
    "                cv2.putText(img,  \n",
    "                    'Sleep',  \n",
    "                    (50, 250),  \n",
    "                    font, 3,  \n",
    "                    (255, 255, 255),  \n",
    "                    2,  \n",
    "                    cv2.LINE_4) \n",
    "        else:\n",
    "            counter=0\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('frame', img) \n",
    "      \n",
    "    # the 'q' button is set as the \n",
    "    # quitting button you may use any \n",
    "    # desired button of your choice \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4a9eda79a4b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mret2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'wait'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "################### test\n",
    "\n",
    "vid = cv2.VideoStream('192.168.1.7/mjpegfeed').start()\n",
    "result='wait'\n",
    "while(True): \n",
    "      \n",
    "    # Capture the video frame \n",
    "    # by frame \n",
    "    ret, frame = vid.read()    \n",
    "    # Display the resulting frame \n",
    "    if(type(frame)!=None):\n",
    "            \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret2,binary=cv2.threshold(gray,45,255,cv2.THRESH_BINARY)\n",
    "        if(result!='wait'):\n",
    "            # result=result+binary\n",
    "            result=cv2.absdiff(result, gray)\n",
    "        else:\n",
    "            result=gray\n",
    "        # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t    # gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\t    # edged = cv2.Canny(gray, 35, 125)\n",
    "        # find the contours in the edged image and keep the largest one;\n",
    "        # we'll assume that this is our piece of paper in the image\n",
    "        cv2.imshow('frame', binary) \n",
    "      \n",
    "    # the 'q' button is set as the \n",
    "    # quitting button you may use any \n",
    "    # desired button of your choice \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "usage: ipykernel_launcher.py [-h] -p SHAPE_PREDICTOR -i IMAGE\nipykernel_launcher.py: error: argument -p/--shape-predictor is required\n"
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "2",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--shape-predictor\", required=True,\n",
    "\thelp=\"path to facial landmark predictor\")\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "\thelp=\"path to input image\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(args[\"shape_predictor\"])\n",
    "\n",
    "rects = detector(gray, 1)\n",
    "\n",
    "\n",
    "\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "\t# initialize the list of (x, y)-coordinates\n",
    "\tcoords = np.zeros((68, 2), dtype=dtype)\n",
    "\t# loop over the 68 facial landmarks and convert them\n",
    "\t# to a 2-tuple of (x, y)-coordinates\n",
    "\tfor i in range(0, 68):\n",
    "\t\tcoords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\t# return the list of (x, y)-coordinates\n",
    "\treturn coords\n",
    "    \n",
    "def rect_to_bb(rect):\n",
    "\t# take a bounding predicted by dlib and convert it\n",
    "\t# to the format (x, y, w, h) as we would normally do\n",
    "\t# with OpenCV\n",
    "\tx = rect.left()\n",
    "\ty = rect.top()\n",
    "\tw = rect.right() - x\n",
    "\th = rect.bottom() - y\n",
    "\t# return a tuple of (x, y, w, h)\n",
    "\treturn (x, y, w, h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'detector' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-866ab5dbb9fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# determine the facial landmarks for the face region, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detector' is not defined"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(0) \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "while(True): \n",
    "      \n",
    "    # Capture the video frame \n",
    "    # by frame \n",
    "    ret, frame = vid.read()    \n",
    " \n",
    "    if(type(frame)!=None):\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        rects = detector(img, 1)\n",
    "        for (i, rect) in enumerate(rects):\n",
    "            # determine the facial landmarks for the face region, then\n",
    "            # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "            # array\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            # convert dlib's rectangle to a OpenCV-style bounding box\n",
    "            # [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "            (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            # show the face number\n",
    "            cv2.putText(image, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            # loop over the (x, y)-coordinates for the facial landmarks\n",
    "            # and draw them on the image\n",
    "            for (x, y) in shape:\n",
    "                cv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('frame', img) \n",
    "      \n",
    "    # the 'q' button is set as the \n",
    "    # quitting button you may use any \n",
    "    # desired button of your choice \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitc2147c82098346c280246e5c84ab2d48",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}