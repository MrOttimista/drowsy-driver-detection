{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/home/adel/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
    }
   ],
   "source": [
    "\n",
    "################ Method One ######### \n",
    "\n",
    "vid = cv2.VideoCapture('http://192.168.1.7:4747/mjpegfeed') \n",
    "eye_cascade = cv2.CascadeClassifier('x.xml')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "counter=0 # to detect sleep or not \n",
    "while(True): \n",
    "      \n",
    "    # Capture the video frame \n",
    "    # by frame \n",
    "    ret, frame = vid.read()    \n",
    " \n",
    "    if(type(frame)!=None): # Async function\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        eyes = eye_cascade.detectMultiScale( img,scaleFactor = 1.1, minNeighbors = 5)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(img,(ex,ey),(ex+ew,ey+eh),(255,0,0),5)\n",
    "\n",
    "        if(eyes==()):\n",
    "            counter+=1\n",
    "            if(counter>7):\n",
    "                cv2.putText(img,  \n",
    "                    'Sleep',  \n",
    "                    (50, 250),  \n",
    "                    font, 3,  \n",
    "                    (255, 255, 255),  \n",
    "                    2,  \n",
    "                    cv2.LINE_4) \n",
    "        else:\n",
    "            counter=0\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('frame', img) \n",
    "      \n",
    "    # the 'q' button is set as the \n",
    "    # quitting button you may use any \n",
    "    # desired button of your choice \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### METHOD TWO ########\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import datetime\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Global vars #####\n",
    "EAR_AVG=0\n",
    "Mouth_AVG=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Initializing Facial Landmarking Predictor ->\n1.44516129032\n0.233458600655\n"
    }
   ],
   "source": [
    "##### Test Phase ########\n",
    "\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "\t# compute the euclidean distances between the two sets of\n",
    "\t# vertical eye landmarks (x, y)-coordinates\n",
    "\tA = dist.euclidean(eye[1], eye[5])\n",
    "\tB = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "\t# compute the euclidean distance between the horizontal\n",
    "\t# eye landmark (x, y)-coordinates\n",
    "\tC = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "\t# compute the eye aspect ratio\n",
    "\tear = (A + B) / (2.0 * C)\n",
    "\n",
    "\t# return the eye aspect ratio\n",
    "\treturn ear\n",
    " \n",
    "# Initializing dlib's face detector (HOG-based)\n",
    "# Creating the facial shape predictor using the 'shape_predictor_68_face_landmarks.dat' file\n",
    "print(\"Initializing Facial Landmarking Predictor ->\")\n",
    "#Detecting the frontal faces\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# Initializing the camera sensor to warm up\n",
    "vid = cv2.VideoCapture('http://192.168.1.7:4747/mjpegfeed') \n",
    "\n",
    "blink_count = 0\n",
    "total = 0\n",
    "\n",
    "# Mouth\n",
    "mouthDistance=[]\n",
    "\n",
    "# Eyes\n",
    "ears=[]\n",
    "\n",
    "counter=0\n",
    "\n",
    "# Looping over all the frames from the webcam stream\n",
    "while True:\n",
    "    # Grabbing the frames\n",
    "\tret, frame = vid.read()\n",
    "\tif(type(frame)!=type(None)):\n",
    "\t\t# Setting the frame size to 500\n",
    "\t\tframe = imutils.resize(frame, width=500)\n",
    "\t\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t\tcv2.putText(frame, 'Stare at the camera', (0, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\t\t# Detecting the faces from the frame\n",
    "\t\trects = detector(frame, 0)\n",
    "\t\tcounter+=1\n",
    "\t\tif(counter>150):\n",
    "\t\t\tbreak\n",
    "\t\t# Looping through each face detection\n",
    "\t\tfor rect in rects:\n",
    "\t\t\tshape = predictor(gray, rect)\n",
    "\t\t\tshape = face_utils.shape_to_np(shape)\n",
    "\n",
    "\t\t\tleftEye = shape[lStart:lEnd]\n",
    "\t\t\trightEye = shape[rStart:rEnd]\n",
    "\t\t\tleftEAR = eye_aspect_ratio(leftEye)\n",
    "\t\t\trightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "\n",
    "\t\t\t##     Mouth\n",
    "\t\t\tdistanceOfMouth=shape[67]-shape[63]\n",
    "\t\t\tif(distanceOfMouth[1]>0):\n",
    "\t\t\t    mouthDistance.append(distanceOfMouth[1])\n",
    "\t\t\telse: \n",
    "\t\t\t\tmouthDistance.append(-1*distanceOfMouth[1])\n",
    "\n",
    "\n",
    "\t\t\t# average the eye aspect ratio together for both eyes\n",
    "\t\t\tear = (leftEAR + rightEAR) / 2.0\n",
    "\t\t\tif(ear>0):\n",
    "\t\t\t\tears.append(ear)\n",
    "\t\t\telse:\n",
    "\t\t\t\tears.append(-1*ear)\n",
    "\n",
    "\t\t\t\t\n",
    "\t\t\t# Looping over the facial landmarks based on their (x,y) coordinates\n",
    "\t\t\t# Drawing a red circle over those landmarks\n",
    "\t\t\tfor (x, y) in shape:\n",
    "\t\t\t\tcv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\t\t# Showing the frame\n",
    "\t\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "\t# Break from loop/end when the 'q' is pressed\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "        \n",
    "# Destroying the windows once the frame display is over\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n",
    "print(sum(mouthDistance)/len(mouthDistance))\n",
    "print(sum(ears)/len(ears))\n",
    "EAR_AVG=sum(ears)/len(ears)\n",
    "Mouth_AVG=sum(mouthDistance)/len(mouthDistance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Initializing Facial Landmarking Predictor ->\n"
    }
   ],
   "source": [
    "##### Second phase #####\n",
    " \n",
    "\n",
    "\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "\t# compute the euclidean distances between the two sets of\n",
    "\t# vertical eye landmarks (x, y)-coordinates\n",
    "\tA = dist.euclidean(eye[1], eye[5])\n",
    "\tB = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "\t# compute the euclidean distance between the horizontal\n",
    "\t# eye landmark (x, y)-coordinates\n",
    "\tC = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "\t# compute the eye aspect ratio\n",
    "\tear = (A + B) / (2.0 * C)\n",
    "\n",
    "\t# return the eye aspect ratio\n",
    "\treturn ear\n",
    " \n",
    "# Initializing dlib's face detector (HOG-based)\n",
    "# Creating the facial shape predictor using the 'shape_predictor_68_face_landmarks.dat' file\n",
    "print(\"Initializing Facial Landmarking Predictor ->\")\n",
    "#Detecting the frontal faces\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# Initializing the camera sensor to warm up\n",
    "vid = cv2.VideoCapture('http://192.168.1.7:4747/mjpegfeed') \n",
    "time.sleep(2.0)\n",
    "\n",
    "blink_count = 0\n",
    "total = 0\n",
    "\n",
    "# Mouth\n",
    "mouthDistance=0\n",
    "mouthCounter=0\n",
    "\n",
    "eyeCounter=0\n",
    "# Looping over all the frames from the webcam stream\n",
    "while True:\n",
    "    # Grabbing the frames\n",
    "\tret, frame = vid.read()\n",
    "\tif(type(frame)!=type(None)):\n",
    "\t\t# Setting the frame size to 500\n",
    "\t\tframe = imutils.resize(frame, width=500)\n",
    "\t\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t\t# cv2.putText(frame, \"Blink Count = \" + str(total), (0, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\t\t# Detecting the faces from the frame\n",
    "\t\trects = detector(frame, 0)\n",
    "\t\t\n",
    "\n",
    "\t\t# Looping through each face detection\n",
    "\t\tfor rect in rects:\n",
    "\t\t\tshape = predictor(gray, rect)\n",
    "\t\t\tshape = face_utils.shape_to_np(shape)\n",
    "\n",
    "\t\t\tleftEye = shape[lStart:lEnd]\n",
    "\t\t\trightEye = shape[rStart:rEnd]\n",
    "\t\t\tleftEAR = eye_aspect_ratio(leftEye)\n",
    "\t\t\trightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "\n",
    "\t\t\t##     Mouth\n",
    "\t\t\tmouthDistance=shape[67]-shape[63]\n",
    "\t\t\tif(mouthDistance[1]>Mouth_AVG):\n",
    "\t\t\t\tmouthCounter+=1\n",
    "\t\t\telse:\n",
    "\t\t\t\tmouthCounter=0\n",
    "\t\t\tif(mouthDistance[1]>Mouth_AVG and mouthCounter>20):\n",
    "\t\t\t\tcv2.putText(frame, \"Yawn\", (0, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\t\t\t# average the eye aspect ratio together for both eyes\n",
    "\t\t\tear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "\t\t\tleftEyeHull = cv2.convexHull(leftEye)\n",
    "\t\t\trightEyeHull = cv2.convexHull(rightEye)\n",
    "\t\t\t# cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "\t\t\t# cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "\t\t\tif(ear<EAR_AVG):\n",
    "\t\t\t\teyeCounter+=1\n",
    "\t\t\telse:\n",
    "\t\t\t\teyeCounter=0\n",
    "\t\t\tif (ear < EAR_AVG and eyeCounter>20):\n",
    "\t\t\t\tcv2.putText(frame, \"Sleeping\", (0, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\t\n",
    "\t\t\t# otherwise, the eye aspect ratio is not below the blink\n",
    "\t\t\t# threshold\n",
    "\n",
    "\n",
    "\t\t\t# Looping over the facial landmarks based on their (x,y) coordinates\n",
    "\t\t\t# Drawing a red circle over those landmarks\n",
    "\t\t\tfor (x, y) in shape:\n",
    "\t\t\t\tcv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\t\t# Showing the frame\n",
    "\t\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "\t# Break from loop/end when the 'q' is pressed\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "        \n",
    "# Destroying the windows once the frame display is over\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitc2147c82098346c280246e5c84ab2d48",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}